## Passo 1 - Clonar projeto 

Para rodar o projeto roda este comando e siga as instru√ß√µes a baixo:
```
git clone https://github.com/LuizZomer/implementacao_data_lakehouse.git
```

### Passo 2 - Rodar o docker compose

Para iniciar as aplica√ß√µes necessarias para uso voc√™ ter√° que rodar este comando na raiz do projeto:
```
docker compose up
```
Este compose foi retirado diretamente da [documenta√ß√£o ofical](https://iceberg.apache.org/spark-quickstart/#docker-compose), apenas sendo modificado esta parte no servi√ßo do spark-iceberg:

```
  ports:
        - 7077:7077 <-- adicionado esta exposi√ß√£o de portas
        - 8888:8888
        - 8080:8080
        - 10000:10000
        - 10001:10001
```

### Passo 3 - Entrar no jupiter notebook

Por meio da URL voc√™ ir√° acessar o jupiter notebook de forma interna no container com a url:
```
http://localhost:8888/tree?
```

### Passo 4 - Copiar csv para o notebook

Na raiz do projeto tem um arquivo csv, com a home do jupyter notebook aberta voc√™ s√≥ arrasta e solta o arquivo. 

### Passo 4 - Rodar o codigo

J√° dentro do jupiter notebook voc√™ criar√° um novo notebook no bot√£o da parte de cima da tela, apartir dele poder√° rodar os codigos que est√£o na main.ipynb, j√° est√£o na ordem correta para funcionar e com coment√°rios explicando seus funcionamento de forma detalhada.

-------------------------------------------------------------------------------------------------------------------------------------

# üöÄ Execu√ß√£o do Projeto

Ap√≥s subir os containers, acesse os seguintes servi√ßos:

---

## üîó Acessos

- **Jupyter Lab**: [http://localhost:8888](http://localhost:8888)  
  O token ser√° exibido no terminal ao iniciar os servi√ßos.

- **MinIO (Painel Web)**: [http://localhost:9000](http://localhost:9000)  
  - Usu√°rio: `minioadmin`  
  - Senha: `minioadmin`

---

## üß™ Como testar

1. Acesse o Jupyter Lab
2. Abra o notebook `notebooks/main.ipynb`
3. Execute as c√©lulas para:

   - Criar tabelas com Apache Iceberg
   - Ingerir dados no MinIO
   - Processar com Spark
   - Persistir dados com versionamento no Lakehouse

---

!!! note "Dica"
    Voc√™ pode modificar os dados de entrada ou transformar os scripts conforme sua necessidade para simula√ß√µes mais avan√ßadas.
