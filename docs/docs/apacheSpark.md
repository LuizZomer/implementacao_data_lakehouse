# Introdu√ß√£o ao Apache Spark com Python

Apache Spark √© uma engine de processamento de dados distribu√≠da e de c√≥digo aberto, projetada para processar grandes volumes de dados de forma r√°pida e eficiente.

## üî• O que √© Spark?

Spark permite executar tarefas de an√°lise de dados em cluster (v√°rios computadores), sendo muito mais r√°pido que abordagens tradicionais como MapReduce, gra√ßas ao uso de mem√≥ria (RAM) para o processamento.

## üêç PySpark

PySpark √© a interface do Apache Spark para a linguagem Python. Ela permite criar aplica√ß√µes de big data utilizando a sintaxe familiar do Python.

### Principais componentes:

- **RDD (Resilient Distributed Dataset):** Estrutura de dados distribu√≠da de baixo n√≠vel.
- **DataFrame:** Tabela distribu√≠da com colunas nomeadas, semelhante ao pandas.
- **Spark SQL:** Permite executar consultas SQL sobre os dados.
- **MLlib:** Biblioteca de machine learning distribu√≠do.
- **GraphX:** Para processamento de grafos (dispon√≠vel apenas em Scala, mas pode ser usado indiretamente em Python).

## ‚úÖ Exemplo b√°sico com PySpark

```python
from pyspark.sql import SparkSession

# Cria√ß√£o de uma SparkSession
spark = SparkSession.builder \
    .appName("Exemplo") \
    .getOrCreate()

# Criando um DataFrame
dados = [("Ana", 30), ("Bruno", 25), ("Carlos", 40)]
colunas = ["Nome", "Idade"]
df = spark.createDataFrame(dados, colunas)

df.show()
